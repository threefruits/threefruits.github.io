<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <!-- <meta name="viewport" content="width=device-width, viewport-fit=cover"> -->

  <title>Anxing Xiao</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link rel="shortcut icon" href="assets/img/icon.png"/>

  <!-- <link href="assets/img/favicon.png" rel="icon"> -->
  <!-- <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon"> -->

  <!-- Google Fonts -->
  <!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet"> -->

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Personal - v4.7.0
  * Template URL: https://bootstrapmade.com/personal-free-resume-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<!-- <body style="width:1080;max-width:1080;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"> -->
<body>
  <!-- ======= Header ======= -->
  <header id="header">
    <div class="container">

      <h1><a href="index.html">Anxing Xiao</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="mr-auto"><img src="assets/img/logo.png" alt="" class="img-fluid"></a> -->
      <h2>Robotics Researcher, CS PhD Student at NUS</h2>
      <!-- <h2>CS PhD Student at National University of Singapore</h2> -->


      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link active" href="#header">Home</a></li>
          <li><a class="nav-link" href="#about">About</a></li>
          <!-- <li><a class="nav-link" href="#resume">Resume</a></li> -->

          <li><a class="nav-link" href="#research">Research</a></li>
          <li><a class="nav-link" href="#publications">Publications</a></li>

          <!-- <li><a class="nav-link" href="#portfolio">Portfolio</a></li> -->
          <li><a class="nav-link" href="#coursework">Coursework</a></li>
          <li><a class="nav-link" href="#misc">Misc</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

      <div class="social-links">
        <a href="https://scholar.google.com/citations?user=qrgIuiEAAAAJ" class="google"><i class="bi bi-google"></i></a>
        <a href="https://www.linkedin.com/in/anxingxiao/" class="linkedin"><i class="bi bi-linkedin"></i></a>
        <a href="https://www.facebook.com/" class="facebook"><i class="bi bi-facebook"></i></a>
        <!-- <a href="#" class="facebook"><img src="assets/img/zhihu.png"></img></a> -->

      </div>

    </div>
  </header><!-- End Header -->

  <!-- ======= About Section ======= -->
  <section id="about" class="about">

    <!-- ======= About Me ======= -->
    <div class="about-me container">

      <div class="row">
        <div class="col-lg-3" data-aos="fade-right" style="margin: 8px 0 -5px 0px;">
          <img src="assets/img/me3.jpg" class="img-fluid" alt="" style="border-radius: 50px;">
        </div>
        <div class="col-lg-9 pt-4 pt-lg-0 content" data-aos="fade-left">
          <h3>Anxing Xiao (ËÇñÂ≤∏Êòü), Robotics Researcher &amp; Engineer</h3>

          <p >
            I am a Ph.D. student in Computer Science at the National University of Singapore, advised by <a href='https://www.comp.nus.edu.sg/~dyhsu/'>Prof. David Hsu</a>. My research primarily focuses on developing compositional reasoning algorithms and multimodal interaction systems for intelligent robots to adaptively perform assistive tasks in dynamic and open human-centered environments . 
            <!-- My research aims to develop autonomous robots that can reason and interact effectively with unstructured environments, especially human-centred environments. -->
          </p>
          <p>
            Previously, I worked as a Research Assistant with <a href='https://www.ee.cuhk.edu.hk/~qhmeng/about.html'>Prof. Max Q.-H. Meng</a>. I received my B.E. in Automation from the Harbin Institute of Technology, Shenzhen in 2021. During my junior year, I was a visiting student at UC Berkeley, working with <a href='https://hybrid-robotics.berkeley.edu/koushil/'>Prof. Koushil Sreenath</a>.              
          </p>
          <p>
            I love playing basketball üèÄ and table tennis üèì in my free time. I am also open to collaborating with people to explore the possibilities of robotics in various fields. Read more about my research or get in touch.
          </p>
          <p style="text-align:center">
            <a href="assets/doc/CV_AnxingXiao.pdf">CV</a> &nbsp&nbsp/&nbsp&nbsp
            <a href="mailto:anxingxiao@u.nus.edu">Email</a> &nbsp&nbsp/&nbsp&nbsp
            <a href="https://scholar.google.com/citations?user=qrgIuiEAAAAJ&hl=en"> Google Scholar </a> &nbsp&nbsp/&nbsp&nbsp
            <a href="https://github.com/threefruits"> Github </a> &nbsp&nbsp/&nbsp&nbsp
            <a href="https://twitter.com/anxingxiao"> Twitter </a> &nbsp&nbsp/&nbsp&nbsp
            <a href="https://bigfive-test.com/result/622f8ea65f3b760009a78ab6"> Personality </a>
          </p>


        </div>
      </div>

    </div><!-- End About Me -->

    <!-- ======= News ======= -->
    <div class="container">

      <div class="section-title">
        <h2>News</h2>
      </div>

      <div class="row">

        <div class="col-lg-12 pt-2 pt-lg-0 content">
          <ul>
          <li><i class="icofont-rounded"></i>06/2023: I'm glad to join <a href="https://adacomp.comp.nus.edu.sg/people/">Adaptive Computing Laboratory</a> led by <a href="https://www.comp.nus.edu.sg/~dyhsu/">Prof. David Hsu</a>.</li>

          <li><i class="icofont-rounded"></i>06/2023: Our work on <a href="https://arxiv.org/abs/2303.06624">Collaborative Trolley Transportation</a> was accepted to IROS'23. Joint work with collaborators from SUSTech. Can't wait to see our system deployed at Shenzhen International Airport!</li>
          <li><i class="icofont-rounded"></i>01/2023: I join National University of Singapore as a PhD student.</li>
          <li><i class="icofont-rounded"></i>01/2023: Our work on <a href="https://arxiv.org/abs/2203.03927">Quadruped Comfortable Guidance</a> was accepted to ICRA'23. Joint work with collaborators from HIT Shenzhen and Tsinghua SIGS.</li>
          <li><i class="icofont-rounded"></i>09/2022: One work on <a href="https://arxiv.org/abs/2203.04541">Uneven Terrain Navigation</a> is accepted to IROS'22. Joint work with collaborators from HIT Shenzhen and Tsinghua SIGS.</li>
          <li><i class="icofont-rounded"></i>02/2022: One work on <a href="https://arxiv.org/abs/2110.06648">Autonomous Trolley Collection Robot</a> is accepted to ICRA'22.</li>
          <li><i class="icofont-rounded"></i>07/2021: I graduate from HIT Shenzhen with Dean's Award and join <a href="http://www.ee.cuhk.edu.hk/~qhmeng/about.html">Prof. Max Q.-H. Meng</a>'s group as a research assistant.</li>
          <li><i class="icofont-rounded"></i>06/2021: Our work on <a href="https://arxiv.org/abs/2103.14300">Robotic Guide Dog</a> is accepted to ICRA'21 and selected to Best Service Robot Paper Finalist.</li>
          <li><i class="icofont-rounded"></i>06/2021: One work on <a href="https://arxiv.org/abs/2107.00773">Optimal Quadruped Jumping</a> is accepted to CASE'21.</li>
          <li><i class="icofont-rounded"></i>08/2019: I am enrolled as a visiting student at UC Berkeley.</li>
          </ul>
        </div>
      </div>

    </div>

    <div class="container">
      <div class="section-title">
        <h2>Honors and Awards</h2>
      </div>
      <div class="row">
        <!-- <div class="col-lg-12 pt-0 pt-lg-0 content">
        <p><font size="4pt" color="orange">I am currently looking for a PhD position in Robotics, Control or Machine Learning.</font>  </p>  -->
        <div class="col-lg-12 pt-2 pt-lg-0 content">
          <ul>
          <!-- <li><i class="icofont-rounded"></i>03/2022: I receive the UBC Four Year Doctoral Fellowship.</li> -->
          <li><i class="icofont-rounded"></i> <strong>Best Service Robot Paper Finalist in ICRA 2021</strong></li>
          <li><i class="icofont-rounded"></i> Dean's Award at HIT Shenzhen, 2021.4</li>
          <li><i class="icofont-rounded"></i> National Scholarship, 2018.10</li>
          <li><i class="icofont-rounded"></i> First-class Undergraduate Academic Scholarship at HIT Shenzhen, 2018-2021</li>
          </ul>
        </div>
      </div>

    </div>

    <div class="services container">

      <div class="section-title">
        <h2>Academic Services</h2>
      </div>
      <div class="col-lg-12 pt-2 pt-lg-0 content">
        <ul>
          <h3 style="margin:15px 0 5px 0px;">Journal Reviewer:</h3>

          <li>IEEE Robotics and Automation Letters (RA-L), 2022, 2023</li>
          <li>IEEE Transactions on Robotics (T-RO), 2021</li>
          <li>Biomimetic Intelligence and Robotics (BIROB), 2021</li>
    
          <h3 style="margin:15px 0 5px 0px;">Conference Reviewer:</h3>
          <li>IEEE International Conference on Robotics and Automation (ICRA), 2022, 2023, 2024</li>
          <li>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022</li>
          <li>IEEE International Conference on Robotics and Biomimetics (ROBIO), 2021</li>
          
          <h3 style="margin:15px 0 5px 0px;">Research Mentorship:</h3>
          <li><strong>Tsinghua SIGS</strong>: Deformable Object Manipulation [Ongoing], Social Robot Navigation [Ongoing], Quadruped Guidance Robot <a href="https://arxiv.org/pdf/2203.03927.pdf">[ICRA 23]</a>, Uneven Terrain Navigation <a href="https://arxiv.org/pdf/2203.04541.pdf">[IROS 22]</a></li>
          <li><strong>SUSTech</strong>: Collaborative Trolley Transportation <a href="https://arxiv.org/pdf/2303.06624.pdf">[IROS 23]</a></li>
        </ul>
      </div>


    </div>



  </section><!-- End About Section -->



  <!-- ======= Services Section ======= -->
  <section id="publications" class="publications">
    <div class="publications container">
      <div class="section-title">
        <h2>Publications</h2>
      </div>

        <div class="row">
        
        <!--<p>&nbsp;</p>-->
        <div class="col-lg-12 pt-2 pt-lg-3 content" >
          
          <!-- <h3><a href="https://scholar.google.com/citations?user=qrgIuiEAAAAJ&hl=en" target="_blank">  Google Scholar</a> </h3>
          <br> -->

          <h3>2023</h3>

          <div class="row">
            <div class="col-lg-12 item">
              
              <p>
              <strong>Collaborative Trolley Transportation System with Autonomous Nonholonomic Robots </strong>
              <br>
              <font color="#4e4e4e" size="4px">Bingyi Xia, Hao Luan, Ziqi Zhao, Xuheng Gao, Peijia Xie, <strong>Anxing Xiao</strong>, Jiankun Wang, Max Q-H Meng</font>
              <br>
              <em>Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023. <font color="#149ddd">Student Advisor.</font>
              </em>
              <br>
              <a href="https://arxiv.org/abs/2303.06624">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=efnPERm0Rco&feature=youtu.be">Video</a>
              </p>
              
            </div>
          </div>

          <div class="row">
            <div class="col-lg-12 item">
              
              <p>
              <strong>Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based Approach </strong>
              <br>
              <font color="#4e4e4e" size="4px">Yanbo Chen, Zhengzhe Xu, Zhuozhu Jian, Gengpan Tang, Yunong Yangli, <strong>Anxing Xiao</strong>, Xueqian Wang, Bin Liang</font>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA) 2023. <font color="#149ddd">Student Advisor.</font>
              </em>
              <br>
              <a href="https://arxiv.org/abs/2203.03927">arXiv</a>
              /
              <a href="https://youtu.be/gd-RcYOqGuo">Video</a>
              </p>
              
            </div>
          </div>
        </div>

        <div class="col-lg-12 pt-2 pt-lg-3 content" >
          
          <h3>2022</h3>
          <div class="row">
            <div class="col-lg-12 item">


              <p>
              <strong>Robotic Autonomous Trolley Collection with Progressive Perception and Nonlinear Model Predictive Control</strong>
              <br>
              <font color="#4e4e4e" size="4px"><strong>Anxing Xiao</strong>*, Hao Luan*, Ziqi Zhao*, Yue Hong, Jieting Zhao, Jiankun Wang, Max Q-H Meng</font>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA) 2022. 
              </em>
              <br>
              <a href="https://arxiv.org/abs/2110.06648">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=6SwjgGvRtno">Video</a>
              </p>
            
              <p>
              <strong>PUTN: A Plane-fitting based Uneven Terrain Navigation Framework</strong>
              <br>
              <font color="#4e4e4e" size="4px">Zhuozhu Jian, Zihong Lu, Xiao Zhou, Bin Lan, <strong>Anxing Xiao</strong>, Xueqian Wang, Bin Liang</font>
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022. <font color="#149ddd">Student Advisor.</font>
              </em>
              <br>
              <a href="https://arxiv.org/abs/2203.04541">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=3ZK-Ut29hLI">Video</a>
              /              
              <a href="https://github.com/jianzhuozhuTHU/putn">Code</a>

              </p>
      

            </div>
          </div>
        </div>

        <div class="col-lg-12 pt-2 pt-lg-3 content" >
          
          <h3>2021</h3>
          <div class="row">
            <div class="col-lg-12 item">

              <p>
              <strong>Robotic Guide Dog: Leading Human with Leash-Guided Hybrid Physical Interaction</strong>
              <br>
              <font color="#4e4e4e" size="4px"><strong>Anxing Xiao</strong>*, Wenzhe Tong*, Lizhi Yang*, Jun Zeng, Zhongyu Li and Koushil Sreenath</font>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA) 2021.  
              </em>
              <br>
              <font color="#ec2f00" size="4px">This paper was the ICRA Best Paper Award Finalist for Service Robotics.</font>
              <br>
              <a href="https://arxiv.org/abs/2103.14300">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=FySXRzmji8Y&t=11s">Video</a>

              Media:
                <a href="https://www.newscientist.com/article/2273390-robot-guide-dog-could-help-people-who-are-blind-navigate/">New Scientist</a> 
                / <a href="https://www.dailymail.co.uk/sciencetech/article-9441691/Robots-Scientists-develop-four-legged-guide-dog-bot-lead-blind-people-obstacles.html">Daily Mail</a> 
                / <a href="https://theindependent.sg/robotic-dog-to-guide-the-blind-and-visually-impaired/">The Independent</a> 
                / <a href="https://techxplore.com/news/2021-04-laser-equipped-robotic-dog-people.html">Tech Xplore</a> 
                / <a href="https://www.dailycal.org/2021/04/12/uc-berkeley-researchers-create-robotic-guide-dog-for-visually-impaired-people/">Daily Californian</a>
              </p>

              <p>
              <strong>Autonomous Navigation with Optimized Jumping through Constrained Obstacles on Quadrupeds</strong>
              <br>
              <font color="#4e4e4e" size="4px">Scott Gilroy, Derek Lau, Lizhi Yang, Ed Izaguirre, Kristen Biermayer, <strong>Anxing Xiao</strong>, Mengti Sun, Ayush Agrawal, Jun Zeng, Zhongyu Li, Koushil Sreenath</font>
              <br>
              <em>IEEE International Conference on Automation Science and Engineering (CASE) 2021. 
              </em>
              <br>
              <a href="https://arxiv.org/abs/2107.00773">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5pzJ8U7YyGc">Video</a>
              </p>

              
             

            </div>
          </div>
        </div>
        
        <!-- <p>&nbsp;</p> -->
        <div class="col-lg-12 pt-3 pt-lg-4 content" >
          <h3>2020</h3>
          <div class="row">
            <div class="col-lg-12 item">
              

              <p>
              <strong>Amphibious Robot‚Äôs Trajectory Tracking with DNN-Based Nonlinear Model Predictive Control</strong>
              <br>
              <font color="#4e4e4e" size="4px">Yaqi Wu*, <strong>Anxing Xiao</strong>*, Haoyao Chen, Shiwu Zhang and Yunhui Liu</font>
              <br>
              <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), Boston, MA, USA, July 2020. 
              </em>
              <br>
              <a href="https://arxiv.org/abs/2107.00773">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5pzJ8U7YyGc">Video</a>
                
            </p>

            </div>
          </div>
        </div>
        
        <!-- <p>&nbsp;</p> -->
        <div class="col-lg-12 pt-3 pt-lg-4 content" >
          <p>
            * co-first author<br>
          </p>
        </div>
        <p>&nbsp;</p>
      </div>
  </section><!-- End Services Section -->

  <!-- ======= Services Section ======= -->
  <section id="research" class="services">
    <div id = 'research_container' class="container">

      <div class="section-title">
        <h2>Research</h2>
      </div>

      <h4 class="">

        My research interests span general purpose robotic algorithms and specialised robotic systems, including interactive decision making, motion planning and control, assistive robotics, and human-robot interaction. I aim to narrow the gap between robotics research and its applications in socially aware scenarios. My long-term research goal is to develop autonomous robots that can reason and interact with the dynamic and open human-centred environments.


      </h4>

      <br>

      <div class="row">

        <div class="col-lg-3 d-flex align-items-stretch mt-4 mt-md-0">
          <a href="#reasoningplanning">
          <div class="icon-box">
            <!-- <div class="icon"><i class="bx bx-file"></i></div> -->
            <h4>Reasoning and Planning</h4>
            <p>Embodied agent that can infer and interact with human-centred environments.</p>
          </div>
        </a>
        </div>

        <div class="col-lg-3 d-flex align-items-stretch mt-4 mt-md-0">
          <a href="#assistiverobotics">
          <div class="icon-box">
            <!-- <div class="icon"><i class="bx bx-file"></i></div> -->
            <h4>Assistive Robotics</h4>
            <p>Improve people‚Äôs lives through compliant and collaborative interactions.</p>
          </div>
        </a>
        </div>

        <div class="col-lg-3 d-flex align-items-stretch mt-4 mt-md-0">
          <a href="#autonomoussystems">
          <div class="icon-box">
            <!-- <div class="icon"><i class="bx bx-tachometer"></i></div> -->
            <h4>Autonomous Systems</h4>
            <p> Equip robots with intelligent system to solve real-world applications.</p>
          </div>
        </a>
        </div>
      
        <div class="col-lg-3 d-flex align-items-stretch mt-4 mt-md-0" >
          <a href="#navigation">
          <div class="icon-box">
            <!-- <img src="assets/img/portfolio/portfolio-1.jpg" class="img-fluid" alt=""> -->
            <!-- <div class="icon"><i class="bx bxl-dribbble"></i></div> -->
            <h4>Robot Navigation</h4>
            <p>Enable robots with complex navigation skills in unstructured environments. </p>
          </div>
        </a>
        </div>



      </div>


    </div>
    
    <div id='reasoningplanning' class="container">
      <br>
      <div >
        <h3>Reasoning and Planning</h3>
      </div>
      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/llmstate.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>LLM-State: Expandable State Representation for Long-horizon Task Planning in the Open World </h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">Collaboration | Preprintf </font>
            </strong>
            <br>
            <font size="4pt" > 
              We propose a novel, expandable state representation that provides continuous expansion and updating of object attributes from the Language Model's inherent capabilities for context understanding and historical action reasoning. Our proposed representation maintains a comprehensive record of an object's attributes and changes, enabling robust retrospective summary of the sequence of actions leading to the current state. We validate our model through experiments across simulated and real-world task planning scenarios, demonstrating significant improvements over baseline methods in a variety of tasks requiring long-horizon state tracking and reasoning.             <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="" target="_blank">arXiv(Comming Soon)</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=QkN-8pxV3Mo" target="_blank">Video</a>
          </p>

        </div>
      </div>

    </div>
    
    <div id='assistiverobotics' class="container">
      <br>
      <div >
        <h3>Assistive Robotics</h3>
      </div>

      <p></p><p></p> <br>


      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/guidedog1.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Robotic Guide Dog: Leading a Human with Leash-Guided Hybrid Physical Interactions</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">First Author | ICRA 2021</font>
            </strong>
            <br>
             <font size="4pt" >We propose a hybrid physical Human-Robot Interaction model that involves leash tension to describe the dynamical relationship in the robot-guiding human system. This hybrid model is utilized in a mixed-integer programming problem to develop a reactive planner that is able to utilize slack-taut switching to guide a blind-folded person to safely travel in a confined space.
              The proposed leash-guided robot framework is deployed on a Mini Cheetah quadrupedal robot and validated in experiments.
             </font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2103.14300" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=FySXRzmji8Y&t=11s" target="_blank">Video</a>
          </p>

        </div>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/guidedog2.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based Approach</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">Student Advisor | ICRA 2023</font>
            </strong>
            <br>
            <font size="4pt" > We propose a novel guidance robot system with a comfort-based concept. 
              To allow humans to be guided safely and more comfortably to the target position in complex environments, our proposed force planner can plan the forces experienced by the human with the force-based human motion model. And the proposed motion planner generate the specific motion command for robot and controllable leash to track the planned force.
              Our system has been deployed on Unitree Laikago quadrupedal platform and validated in real-world scenarios. </font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2203.03927" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=Xroov-UASC0" target="_blank">Video</a>
          </p>
        </div>
      </div>



    </div>

    <div id='autonomoussystems' class="container">
      <br>
      <div>
        <h3>Autonomous Systems</h3>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/trolley_collect.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Robotic Autonomous Trolley Collection with Progressive Perception and Nonlinear Model Predictive Control</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">First Author | ICRA 2022</font>
            </strong>
            <br>
            <font size="4pt" > We propose a novel mobile manipulation system with applications in luggage trolley collection. 
              The proposed system integrates a compact hardware design and a progressive perception stragy and MPC-based planning framework, enabling the system to efficiently and robustly collect trolleys in dynamic and complex environments.
              We demonstrate our design and framework by deploying the system on actual trolley collection tasks, and their effectiveness and robustness are experimentally validated. </font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2110.06648" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=6SwjgGvRtno" target="_blank">Video</a>
          </p>

        </div>
      </div>
      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/trolley_trans.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Collaborative Trolley Transportation System with Autonomous Nonholonomic Robots </h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">Student Advisor | IROS 2023</font>
            </strong>
            <br>
            <font size="4pt" > 
              This paper presents an autonomous nonholonomic multi-robot system and a hierarchical autonomy framework for collaborative luggage trolley transportation. This framework finds kinematic-feasible paths, computes online motion plans, and provides feedback that enables the multi-robot system to handle long lines of luggage trolleys and navigate obstacles and pedestrians while dealing with multiple inherently complex and coupled constraints. We demonstrate the designed collaborative trolley transportation system through practical transportation tasks in complex and dynamic environments.
              <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2303.06624" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=efnPERm0Rco&feature=youtu.be" target="_blank">Video</a>
          </p>

        </div>
      </div>

    </div>



    <div id='navigation' class="container">
      <br>
      <div >
        <h3>Robot Navigation</h3>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/navigation.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>PUTN: A Plane-fitting based Uneven Terrain Navigation Framework</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">Student Advisor | IROS 2022</font>
            </strong>
            <br>
            <font size="4pt" > We proposed a plane-fitting based uneven terrain navigation framework(PUTN) which is designed for effectively navigating on uneven terrain. 
              A new terrain assessment with plane-fitting to evaluate the traversability of the terrain is proposed.
              Combined with the informed-RRT* and this terrain assessment method, a new planning algorithm, PF-RRT*, is proposed. By using Gaussian Process, the traversability of the dense path is generated given the sample tree generated by PF-RRT*.
              The results verify the advantages of the PF-RRT* algorithm and the practicability of PUTN.</font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2203.04541" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=3ZK-Ut29hLI" target="_blank">Video</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/jianzhuozhuTHU/putn" target="_blank">Code</a>

          </p>

        </div>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/jump.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Autonomous Navigation with Optimized Jumping through Constrained Obstacles on Quadrupeds</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey">Collaboration | CASE 2021</font>
            </strong>
            <br>
            <font size="4pt" >
              We developed an end-to-end framework that enabled multi-modal transitions between walking and jumping skills. 
              Using multi-phased collocation based nonlinear optimization, optimal trajectories were generated for the quadrupedal robot while avoiding obstacles and allowing the robot to jump through window-shaped obstacles. 
              An integrated state machine, path planner, and jumping and walking controllers enabled the Mini-Cheetah to jump over obstacles and navigate previously nontraversable areas.</font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2107.00773" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=5pzJ8U7YyGc" target="_blank">Video</a>
          </p>

        </div>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-4 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/amphi.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Hexapod Robotic‚Äôs Trajectory Tracking with DNN-Based Nonlinear Model Predictive Control</h4>
          <p class="font-italic">
            <strong>
              <font size="4pt" color="grey"> Collaboration | AIM 2021 </font>
            </strong>
            <br>
            <font size="4pt" >We first contribute a well design deep neural network (DNN) as a precise black-box kinematic model of the amphibious robot. Then, we design a DNN based nonlinear model predictive controller which obtains the robot‚Äôs real-time moving command by iterative optimization. The simulation results indicate the proposed controller is superior to the basic controller in the robot‚Äôs tracking efficiency and accuracy.</font>
            <br>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/9159003" target="_blank">Paper</a>
            <!-- <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.youtube.com/watch?v=FySXRzmji8Y&t=11s" target="_blank">Video</a> -->
          </p>
          </p>
        </div>
      </div>



    </div>




    <!-- <div class="container">

      <div class="section-title">
        <h2>Invited Talks</h2>
      </div>


    </div> -->

    <div class="container">

      <div class="section-title">
        <h2>Media</h2>
      </div>

      <div class="row">

        <div class="col-lg-12 pt-2 pt-lg-0 content">
          <h2>Robotic Guide Dog [Apr. 2021]</h2>
          <ul>
          <!-- <li><i class="icofont-rounded"></i>03/2022: I receive the UBC Four Year Doctoral Fellowship.</li> -->
          <li><i class="icofont-rounded"></i><a href= "https://techxplore.com/news/2021-04-robotic-dog-individuals.html" target="_blank">Tech Xplore</a> </li>
          <li><i class="icofont-rounded"></i><a href= "https://mp.weixin.qq.com/s/U0c1rOuDCF3dgkoG0zMx9Q" target="_blank">MIT Technology Review Chinese (DeepTech)</a></li>
          <li><i class="icofont-rounded"></i><a href= "https://www.newscientist.com/article/2273390-robot-guide-dog-could-help-people-who-are-blind-navigate/" target="_blank"> New Scientist</a></li>
          <li><i class="icofont-rounded"></i><a href= "https://www.dailymail.co.uk/sciencetech/article-9441691/Robots-Scientists-develop-four-legged-guide-dog-bot-lead-blind-people-obstacles.html" target="_blank">Daily Mail</a> </li>
          <li><i class="icofont-rounded"></i><a href= "https://theindependent.sg/robotic-dog-to-guide-the-blind-and-visually-impaired/" target="_blank">The Independent</a> </li>
          <li><i class="icofont-rounded"></i><a href= "https://techxplore.com/news/2021-04-laser-equipped-robotic-dog-people.html" target="_blank">Tech Xplore</a> </li>
          <li><i class="icofont-rounded"></i><a href= "https://www.dailycal.org/2021/04/12/uc-berkeley-researchers-create-robotic-guide-dog-for-visually-impaired-people/" target="_blank">Daily Californian</a> </li>
          </ul>
        </div>
      </div>

    </div><!-- End Skills -->

  </section> 




  <!-- ======= Coursework Section ======= -->
  <section id="coursework" class="coursework">
    <div class="container">
      <div class="section-title">
        <h2>Teaching</h2>
      </div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>
          <li><i class="icofont-rounded-right"></i>NUS CS2109S Introduction to AI and Machine Learning (24 Spring)</br></li>       
        </ul>
      </div>

      <br>

      <div class="section-title">
        <h2>Selected Coursework</h2>
      </div>
      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Artificial Intelligence:</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>
          <li><i class="icofont-rounded-right"></i>NUS CS6216: Graph Machine Learning (Prof. Xavier Bresson)</br></li>       
          <li><i class="icofont-rounded-right"></i>NUS CS5340: Probabilistic Graphical Models (Prof. Harold Soh)</li>
          <li><i class="icofont-rounded-right"></i>NUS CS5242: Neural Networks and Deep Learning (Prof. Yang You)</br></li>       
          <li><i class="icofont-rounded-right"></i>Berkeley CS294: Geometry and Learning for 3D Vision (Prof. Yi Ma)</li>
          <li><i class="icofont-rounded-right"></i>HIT AUTO2012: Introduction to Machine Learning  </li>
        </ul>
      </div>

      <div class="col-lg-12 pt-1 pt-lg-0 content"><h3>Control:</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>

          <li><i class="icofont-rounded-right"></i>Berkeley EE291E: Hybrid System and Intelligent Control (Prof. S. Shankar Sastry)</li>
          <li><i class="icofont-rounded-right"></i>Berkeley ME232: Advanced Control Systems (Prof. Kameshwar Poolla)</li>
          <li><i class="icofont-rounded-right"></i>Berkeley EE220C: State Estimation and Optimal Control (Prof. Mark Mueller)</li>
          <li><i class="icofont-rounded-right"></i>Berkeley EE128: Feedback Control System (Prof. Ronald Fearing)</li>
        </ul>
      </div>

      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Robotics:</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>
          <li><i class="icofont-rounded-right"></i>NUS CS6244: Using Language Models in Visual Perception (Prof. Angela Yao)</br></li>       
          <li><i class="icofont-rounded-right"></i>Berkeley EECS106B: Robotic Manipulation and Interaction (Prof. Ruzena Bajcsy, Prof. S. Shankar Sastry)</li>
          <li><i class="icofont-rounded-right"></i>Berkeley ME102B: Mechatronics Design (Prof. Hannah Stuart)</li>
          <li><i class="icofont-rounded-right"></i>HITSZ AUTO2004: Design and Practice of Robotic System</li>
        </ul>
      </div>
      

      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Theoretical:</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>
          <li><i class="icofont-rounded-right"></i>NUS CS5461: Algorithmic Mechanism Design (Prof. Warut Suksompong)</li>

          <li><i class="icofont-rounded-right"></i>NUS CS6235: Mathematical Toolkit for CS Theory Research. (Prof. Jonathan Scarlett)</li>
          <li><i class="icofont-rounded-right"></i>Berkeley E231: Mathematical Methods in Engineering. (Prof. Andrew Packard, Prof. Murat Arcak, Prof. Mark Mueller)</li>
          <li><i class="icofont-rounded-right"></i>HIT MATH1009: Advanced Linear Algebra I, II (Âº†Ë¥§Áßë)</li>
          <li><i class="icofont-rounded-right"></i>HIT MATH1010: Mathematical Analysis I, II, III (‰∏•Ë¥®ÂΩ¨)</li> 
          <li><i class="icofont-rounded-right"></i>HIT EMEC1002: Theoretical Mechanics</li>          
        </ul>
      </div>


    </div>
  </section>
  
  <!-- ======= Services Section ======= -->
  <section id="misc" class="misc">
    <div class="misc container">
      <div class="section-title">
        <h2>Misc</h2>
      </div>
      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Email</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <p>
          The best way to reach me is via email: 
          <br>
          anxingxiao [at] gmail.com (Primary)
          <br>
          anxingxiao [at] u.nus.edu. (Academic)
          <br>
          anxingx [at] comp.nus.edu.sg (Research)
        </p>
      </div>

      <p></p><p></p> 


      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Office</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <p>
        You can often find me at:
        <br>
        AI Lab 1, COM3 Building, 2nd Floor, Room 02-21, C95. (Primary)
        <br>
        Robot Living Studio, COM1 Building, 1nd Floor, Room 01-24.
        </p>
      </div>

      <p></p><p></p>


      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Links</h3></div>
      <div class="col-lg-12 pt-1 pt-lg-0 content">
        <ul>
          <li><i class="icofont-rounded-right"></i>
            <a href="https://adacomp.comp.nus.edu.sg/"> Adaptive Computing Laboratory at National University of Singapore </a>
          </li>
          <li><i class="icofont-rounded-right"></i>
            <a href="https://www.comp.nus.edu.sg/cs/"> Department of Computer Science at National University of Singapore </a>
          </li>
          <li><i class="icofont-rounded-right"></i>
            <a href="https://ssi.nus.edu.sg/#about"> Smart Systems Institute at National University of Singapore </a>
          </li>
          
          <li><i class="icofont-rounded-right"></i>
            <a href="https://hybrid-robotics.berkeley.edu/index.html"> Hybrid Robotics Group at University of Califonia, Berkeley </a>
          </li>
        </ul>
      </div>

      <p></p><p></p> 


      <div class="col-lg-12 pt-0 pt-lg-0 content"><h3>Interesting Course Projects</h3></div>

      <div class="row">
        <div class="col-lg-3 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/sonarmcl.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-9 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Localisation For Underwater Vehicles Using a Forward-Looking Sonar</h4>
          <p class="font-italic">
            <strong>
              <em >NUS CS5340 Uncertainty Modelling in AI</em>
            </strong>
          </p>
          <p>
             <font size="4pt" >
              Utilized Markov Random Fields (MRF) to denoise forward-looking sonar (FLS) images and Bayesian optimization to estimate the odometry; Implemented the Monte Carlo Localisation algorithm for Autonomous Underwater Vehicles (AUVs) on data collected from AUVs operating in open water.
             </font>
            <br>
          </p>
          <!-- <div class=" btn-links">
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://proceedings.neurips.cc/paper/2020/hash/e4d8163c7a068b65a64c89bd745ec360-Abstract.html" target="_blank">Paper</a>
            <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2102.09117" target="_blank">Video</a>
          </div> -->
        </div>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-3 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/reachavoid.gif" class="img-fluid" alt="">
        </div>
        <div class="col-lg-9 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Reach-Avoid Games via Deep Reinforcement Learning</h4>
          <p class="font-italic">
            <strong>
              <em >HIT Auto2012 Introduction to Maching Learning</em>
            </strong>
          </p>
          <p>
             <font size="4pt" >
              Designed training pipelines to solve reach-avoid games using the Soft Actor Criticism (SAC) algorithm;
              The model was trained in Robotarium simulations and transferred to real-world experiments;
              Learned policy performed better than the baseline MPC method and human policy in both defense and attack tasks.             </font>
            <br>
          </p>

        </div>
      </div>

      <p></p><p></p> <br>

      <div class="row">
        <div class="col-lg-3 pt-lg-2">
        <!--<div class="col-lg-4" data-aos="fade-right">-->
          <img src="assets/img/demo/scanner.gif"  class="img-fluid" alt="">
        </div>
        <div class="col-lg-9 pt-4 pt-lg-0 content">
        <!--<div class="col-lg-8 pt-4 pt-lg-1 content" data-aos="fade-left">-->
          <h4>Automatic notesbook scanner</h4>
          <p class="font-italic">
            <strong>
              <em >Berkeley ME102B Mechatronics Design</em>
            </strong>
          </p>
          <p>
             <font size="4pt" >
              Completed 3D model design in SolidWorks and manufactured parts of the scanner by 3D printing and laser cutting;
              Integrated electronics components to achieve autonomous page turning and scanning;
              Processed the scanner image with perspective transformation and adaptive threshold using OpenCV.
                           </font>
            <br>
          </p>

        </div>
      </div>

      <p></p><p></p> <br>

    </div>
  </section>
  <!-- End Services Section -->

  

  <div class="credits">
    &copy; Anxing Xiao (01/2024)
    <br>
    <!-- All the links in the footer should remain intact. -->
    <!-- You can delete the links only if you purchased the pro version. -->
    <!-- Licensing information: https://bootstrapmade.com/license/ -->
    <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/personal-free-resume-bootstrap-template/ -->
    Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
  </div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>